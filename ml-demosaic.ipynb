{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filtermasken generator\n",
    "from math import ceil\n",
    "\n",
    "xtrans=\"\"\"gbggrg\n",
    "rgrbgb\n",
    "gbggrg\n",
    "grggbg\n",
    "bgbrgr\n",
    "grggbg\n",
    "\"\"\"\n",
    "bayer = \"\"\"gr\n",
    "bg\"\"\"\n",
    "\n",
    "def filtermask_from_str(w,h,pattern=bayer):\n",
    "    d = {\"r\":[1,0,0],\"g\":[0,1,0],\"b\":[0,0,1]}\n",
    "    a = np.array([[d[y] for y in x] for x in pattern.splitlines()]).astype(\"float32\")\n",
    "    (ph,pw,_) = a.shape\n",
    "    return np.tile(a,(ceil(h/ph),ceil(w/pw),1))[0:h,0:w]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsdaten vorbereiten\n",
    "Bilder zunächst auf 50% runterskalieren um mögliche Mängel des Demosaic Verfahrens der Kamera zu verstecken. Dann wird das Bild nachträglich in eine Form gebracht die einem Bayer Sensor entspricht vor dem Demosaic Verfahren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from random import seed,shuffle\n",
    "\n",
    "tile_size=32\n",
    "\n",
    "training_dataset=[]\n",
    "\n",
    "for p in Path(\"./training_images\").iterdir():\n",
    "    if p.is_file():\n",
    "        # bilder laden und in numpy array umwandeln\n",
    "        im = Image.open(p).convert('RGB')\n",
    "        # bild runterskalieren um effekte vom ursprünglichen demosaic verfahren zu minimieren\n",
    "        im = im.resize((im.width//2,im.height//2),Image.LANCZOS)\n",
    "        \n",
    "        im_a = np.asarray(im,'float32')\n",
    "        im_a/=255\n",
    "        im_b = im_a.copy()\n",
    "        \n",
    "        # Bayer Pattern erzeugen\n",
    "        im_a*=filtermask_from_str(im.width,im.height)\n",
    "                \n",
    "        #bild aufteilen \n",
    "        (h,w,_) = im_a.shape\n",
    "        (h,w) = (h//tile_size,w//tile_size)\n",
    "        \n",
    "        for x,y in product(range(w),range(h)):\n",
    "            tile_a = im_a[y*tile_size:(y+1)*tile_size, x*tile_size:(x+1)*tile_size,].copy()\n",
    "            tile_b = im_b[y*tile_size:(y+1)*tile_size, x*tile_size:(x+1)*tile_size,].copy()\n",
    "            training_dataset.append((tile_a,tile_b))\n",
    "\n",
    "seed(42)\n",
    "shuffle(training_dataset)\n",
    "\n",
    "train_a,train_b = zip(*training_dataset)\n",
    "\n",
    "train_a = np.array(train_a)\n",
    "train_b = np.array(train_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mosaic zur Kontrolle anzeigen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 200\n",
    "\n",
    "plt.figure(figsize=(16,16*2))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_a[idx],interpolation=\"nearest\")\n",
    "plt.text(16,-2,\"Bayer Pattern\",fontsize=20,horizontalalignment='center')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(train_b[idx],interpolation=\"nearest\")\n",
    "plt.text(16,-2,\"RGB Image\",fontsize=20,horizontalalignment='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell erstellen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow soll sich nur den Speicher holen den es braucht anstatt sich alles unter den Nagel zu reißen\n",
    "([Code aus Tensorflow Guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow as tf\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "      try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "          tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "      except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Hatte PSNRLoss in einem anderem Projekt benutzt und war besser als die builtin metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNRLoss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    PSNR is Peek Signal to Noise Ratio, which is similar to mean squared error.\n",
    "    It can be calculated as\n",
    "    PSNR = 20 * log10(MAXp) - 10 * log10(MSE)\n",
    "    When providing an unscaled input, MAXp = 255. Therefore 20 * log10(255)== 48.1308036087.\n",
    "    However, since we are scaling our input, MAXp = 1. Therefore 20 * log10(1) = 0.\n",
    "    Thus we remove that component completely and only compute the remaining MSE component.\n",
    "    \"\"\"\n",
    "    return -10. * K.log(K.mean(K.square(y_pred - y_true))) / K.log(10.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vorerst nur ein sehr einfacher Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,Conv2DTranspose,Input\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "inp = Input(shape=(tile_size,tile_size,3))\n",
    "\n",
    "conv1 = Conv2D(64,(3,3), activation='relu',strides=(2,2),padding='same')(inp)\n",
    "deconv1 = Conv2DTranspose(64,(3,3),activation='relu', strides=(2,2), padding='same')(conv1)\n",
    "out = Conv2DTranspose(3,(5,5),activation='linear',padding='same')(deconv1)\n",
    "\n",
    "model = Model(inputs=inp, outputs=out)  \n",
    "model.compile(loss=keras.losses.mean_squared_error,\n",
    "             optimizer=keras.optimizers.Adam(),\n",
    "             metrics=[PSNRLoss])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5)\n",
    "hist =  model.fit(train_a, train_b,\n",
    "                    batch_size=32,\n",
    "                    epochs=200,\n",
    "                    shuffle=True,\n",
    "                    validation_split=0.9,\n",
    "                    callbacks=[early_stopping],\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper\n",
    "helper.plot_model(hist,size=(16,6))\n",
    "\n",
    "x = max(hist.history['PSNRLoss'])\n",
    "print(f\"maximum PSNRLoss: {x:.4f}\")\n",
    "x = min(hist.history['loss'])\n",
    "print(f\"minimum loss: {x:f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testlauf\n",
    "(ist natürlich verfälscht da hier ein bild aus dem trainingsdatensatz verwendet wird)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 12\n",
    "\n",
    "plt.figure(figsize=(16,16*3))\n",
    "\n",
    "#original bild anzeigen\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(train_b[i],interpolation=\"nearest\")\n",
    "plt.text(16,-2,\"Original\",fontsize=20,horizontalalignment='center')\n",
    "\n",
    "#demosicing durch den autoencoder\n",
    "plt.subplot(1,3,2)\n",
    "decoded = model.predict(train_a[i:i+1])\n",
    "decoded = np.clip(decoded,0,1)\n",
    "plt.imshow(decoded[0])\n",
    "plt.text(16,-2,\"ML-Demosaic\",fontsize=20,horizontalalignment='center')\n",
    "\n",
    "#opencv demosaicing algorithmus zum vergleich (irgendwas stimmt hier noch nicht)\n",
    "plt.subplot(1,3,3)\n",
    "import cv2\n",
    "(h,w,_) = train_a[i].shape\n",
    "# rgb bayer bild in graustufen umwandeln\n",
    "a = np.zeros((h,w))\n",
    "for x in range(h):\n",
    "    for y in range(w):\n",
    "        a[x,y] = sum(train_a[i][x,y]) # summe der 3 kanäle nehmen da 2 kanäle immer 0 sind\n",
    "a = (a * 255).astype(\"uint8\")\n",
    "b = cv2.cvtColor(a, cv2.COLOR_BAYER_GB2RGB)\n",
    "plt.imshow(b,interpolation=\"nearest\")\n",
    "plt.text(16,-2,\"OpenCV Demosaicing\",fontsize=20,horizontalalignment='center')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
